# cnn 三层神经网络
import tensorflow as tf
# import numpy as np
# import cv2
from tensorflow.examples.tutorials.mnist import input_data
tf.compat.v1.disable_eager_execution()
# load data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
# input
imageInput = tf.compat.v1.placeholder(tf.float32, [None, 784])     # 28*28
labelInput = tf.compat.v1.placeholder(tf.float32, [None, 10])       # knn
# 维度调整 [None,784] -> M*28*28*1 2D->4D 28*28 wh  1--channel M - imgNum
imageInputReshape = tf.reshape(imageInput, [-1, 28, 28, 1])
# 卷积 w0 : 卷积内核 5*5 output:32 in:1
w0 = tf.Variable(tf.compat.v1.truncated_normal([5, 5, 1, 32], stddev=0.1))  # 高斯分布的变量，方差0.1
b0 = tf.Variable(tf.constant(0.1, shape=[32]))    # 偏置
# 输入层 layer1 = 激励函数 + 卷积运算
layer1 = tf.nn.relu(tf.nn.conv2d(imageInputReshape, w0, strides=[1, 1, 1, 1], padding='SAME') + b0)   # relu保持非线性
# M*28*28*32 SAME-》边界
# 隐藏层 pool 采样 数据量减少 M*28*28*32 / [1 4 4 1 ]=M*7*7*32  strides=[1 4 4 1 ]对应维度的采样步长
layer1_pool = tf.nn.max_pool(layer1, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding='SAME')
# layer2 -> out  : 激励函数+ 乘加运算：softmax
# [7*7*32, 1024]
w1 = tf.Variable(tf.compat.v1.truncated_normal([7*7*32, 1024], stddev=0.1))
b1 = tf.Variable(tf.constant(0.1, shape=[1024]))
h_reshape = tf.reshape(layer1_pool, [-1, 7*7*32])     # M*7*7*32->N*N1
# [N*7*7*32] [7*7*32, 1024] = N*1024
h1 = tf.nn.relu(tf.matmul(h_reshape, w1) + b1)
# 输出层 sofMax-》预测
w2 = tf.Variable(tf.compat.v1.truncated_normal([1024, 10], stddev=0.1))
b2 = tf.Variable(tf.constant(0.1, shape=[10]))
predict = tf.nn.softmax(tf.matmul(h1, w2) + b2)  # N*1024 1024*10 = N*10
# N*10(概率）N1[0.1 0.2 ..]  0-9出现的概率
# label [ 1 0 0 0 .. ]   tf.compat.v1.log(predict) 取对数减少运算量 也是为softMax做准备
loss0 = labelInput * tf.compat.v1.log(predict)
loss1 = 0
for m in range(0, 500):   # test 100
    for n in range(0, 10):
        loss1 = loss1 - loss0[m, n]
loss = loss1/500
# train
train = tf.compat.v1.train.GradientDescentOptimizer(0.01).minimize(loss)  # 梯度下降法 训练
# run
with tf.compat.v1.Session() as sess:
    sess.run(tf.compat.v1.global_variables_initializer())
    for i in range(100):
        images, labels = mnist.train.next_batch(500)
        sess.run(train, feed_dict={imageInput: images, labelInput: labels})
        predict_test = sess.run(predict, feed_dict={imageInput: mnist.test.images, labelInput: labels})
        # 下载图片
        # cv2.imshow('src', imageInputReshape[i])
        # cv2.waitKey(100)
        # cv2.destroyWindow('src')
        # cv2.imwrite('%s.jpg' % str(i), images[i])
        acc = tf.equal(tf.compat.v1.arg_max(predict_test, 1), tf.compat.v1.arg_max(mnist.test.labels, 1))
        acc_float = tf.reduce_mean(tf.cast(acc, tf.float32))
        acc_result = sess.run(acc_float, feed_dict={imageInput: mnist.test.images, labelInput: mnist.test.labels})
        print(acc_result)  # 检测概率